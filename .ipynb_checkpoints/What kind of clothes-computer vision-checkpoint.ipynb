{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d194d792-85f4-461b-aacf-bb6b9ad7f86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1c841b8-7a59-4ef5-9eed-ff80675ebf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "transforms= T.Compose([T.ToTensor(),T.Normalize([0.5],[0.5])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e0a4d31a-249e-4d6a-9d53-7b7b58e57de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set=torchvision.datasets.FashionMNIST(root=r'C:\\Users\\alibr\\OneDrive\\Desktop\\pytorch' ,download=True,train=True,transform=transforms )\n",
    "test_set=torchvision.datasets.FashionMNIST(root=r'C:\\Users\\alibr\\OneDrive\\Desktop\\pytorch' ,download=True,train=False,transform=transforms)\n",
    "train_set,val_set=torch.utils.data.random_split(train_set,[50000,10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c3674e3e-dabf-4546-957b-c97bbb16e287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
     ]
    }
   ],
   "source": [
    "train_loader=torch.utils.data.DataLoader(train_set,batch_size=64,shuffle=True,num_workers=2)\n",
    "val_loader=torch.utils.data.DataLoader(val_set,batch_size=64,shuffle=True,num_workers=2)\n",
    "test_loader=torch.utils.data.DataLoader(test_set,batch_size=64,shuffle=True,num_workers=2)\n",
    "\n",
    "print(len(test_loader.dataset.classes))  # Number of classes\n",
    "print(test_loader.dataset.classes)  # List of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "144d2a68-e29f-423e-85ab-0f4baf405c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStop:\n",
    "    def __init__(self, patience=10):\n",
    "        # Number of epochs to wait without improvement before stopping\n",
    "        self.patience = patience\n",
    "        # Counter for epochs without improvement\n",
    "        self.steps = 0\n",
    "        # Initialize the minimum validation loss to infinity\n",
    "        self.min_loss = float('inf')\n",
    "\n",
    "    def stop(self, val_loss):\n",
    "        # Check if the current validation loss is lower than the previous minimum\n",
    "        if val_loss < self.min_loss:\n",
    "            # Update the minimum validation loss\n",
    "            self.min_loss = val_loss\n",
    "            # Reset the counter since improvement was seen\n",
    "            self.steps = 0\n",
    "        else:\n",
    "            # Increment the counter as no improvement was observed\n",
    "            self.steps += 1\n",
    "        \n",
    "        # If the number of non-improving epochs reaches patience, stop training\n",
    "        if self.steps >= self.patience:\n",
    "            return True  # Stop training\n",
    "        else:\n",
    "            return False  # Continue training\n",
    "\n",
    "# Example usage of EarlyStopping:\n",
    "stoper = EarlyStop(patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6789910d-178b-4a58-844a-0be1322567a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(28*28,256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256,128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128,64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64,10).to(device)\n",
    ")\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "loss_fn=nn.CrossEntropyLoss()  \n",
    "#In fact, the softmax layer is also inside CrossEntropyLoss, and we will not write it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "489bcc11-647c-4dae-b763-9faaf21ad930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch():\n",
    "    tloss=0\n",
    "    for imgs,labels in  train_loader:\n",
    "        imgs= imgs.reshape(-1,28*28).to(device)\n",
    "        labels=labels.reshape(-1,).to(device)\n",
    "        preds=model(imgs)\n",
    "        loss=loss_fn(preds,labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tloss+=loss.detach()\n",
    "    return tloss\n",
    "\n",
    "def val_epoch():\n",
    "    vloss=0\n",
    "    for imgs,labels in val_loader:\n",
    "        imgs= imgs.reshape(-1,28*28).to(device)\n",
    "        labels=labels.reshape(-1,).to(device)\n",
    "        preds=model(imgs)\n",
    "        loss=loss_fn(preds,labels)\n",
    "        vloss+=loss.detach()\n",
    "    return vloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "723bb878-d90e-4f8b-be95-4f898cdb73a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch 1 , tlossis 196.17288208007812 , vloss is 35.85649108886719\n",
      "at epoch 2 , tlossis 186.2237091064453 , vloss is 38.472206115722656\n",
      "at epoch 3 , tlossis 179.30381774902344 , vloss is 39.436431884765625\n",
      "at epoch 4 , tlossis 170.35552978515625 , vloss is 40.2406120300293\n",
      "at epoch 5 , tlossis 161.9225616455078 , vloss is 39.65324401855469\n",
      "at epoch 6 , tlossis 156.2237091064453 , vloss is 40.34807586669922\n",
      "at epoch 7 , tlossis 148.79942321777344 , vloss is 38.720001220703125\n",
      "at epoch 8 , tlossis 140.66334533691406 , vloss is 43.64981460571289\n",
      "at epoch 9 , tlossis 135.5573272705078 , vloss is 43.89677810668945\n"
     ]
    }
   ],
   "source": [
    "#Using the functions we defined, we do the training\n",
    "for i in range (1,10):\n",
    "    tloss=train_epoch()\n",
    "    vloss = val_epoch()\n",
    "    print(f\"at epoch {i} , tlossis {tloss} , vloss is {vloss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a367c48f-4cf2-48e1-aac8-0bbfd5d34444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 the prediction is 9\n",
      "2 the prediction is 2\n",
      "1 the prediction is 1\n",
      "1 the prediction is 1\n",
      "6 the prediction is 6\n",
      "1 the prediction is 1\n",
      "4 the prediction is 4\n",
      "6 the prediction is 6\n",
      "5 the prediction is 5\n",
      "7 the prediction is 7\n",
      "4 the prediction is 4\n",
      "5 the prediction is 5\n",
      "7 the prediction is 5\n",
      "3 the prediction is 3\n",
      "4 the prediction is 4\n",
      "1 the prediction is 1\n",
      "2 the prediction is 2\n",
      "4 the prediction is 2\n",
      "8 the prediction is 8\n",
      "0 the prediction is 0\n"
     ]
    }
   ],
   "source": [
    "#To get the prediction values, imgs and labels inputs should be one-dimensional\n",
    "for i in range(20):\n",
    "    img,labels=test_set[i]\n",
    "    img=img.reshape(-1,28*28).to(device)\n",
    "    pred=model(img)\n",
    "    index_pred=torch.argmax(pred,dim=1) #argmax causes the index to give us the largest value\n",
    "    idx=index_pred.item()\n",
    "    print(f\"{labels} the prediction is {idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7acafae4-de2f-42b8-9cfb-e40cba403306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8785828025477707\n"
     ]
    }
   ],
   "source": [
    "result= []\n",
    "for imgs,labels in test_loader:\n",
    "    imgs= imgs.reshape(-1,28*28).to(device)\n",
    "    labels= (labels).reshape(-1,).to(device)\n",
    "    preds=model(imgs)\n",
    "    #print(preds)\n",
    "    pred10=torch.argmax(preds,dim=1)\n",
    "    #print(pred10) \n",
    "    correct =(pred10==labels) #True or False\n",
    "    result.append(correct.detach().cpu().numpy().mean())\n",
    "#print(result)\n",
    "\n",
    "accuracy = np.array(result).mean()\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441b63c7-f0fc-4132-b15d-475e21607e07",
   "metadata": {},
   "source": [
    "### Accuracy Result\n",
    "\n",
    "The model achieved an **accuracy** of:\n",
    "\n",
    "**`0.8786`** \n",
    "\n",
    "This value represents the average accuracy calculated over all batches in the test dataset.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
