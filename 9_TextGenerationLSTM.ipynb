{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0pSjfHSO+RiA4Ylo4GVyv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrhamedani/Gen-AI-projects-Pytorch/blob/main/9_TextGenerationLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jgleZ0svM3Q",
        "outputId": "dffacc95-44fb-402f-c125-85f8cb49b3a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['H', 'i', ',', ' ', 't', 'h', 'e', 'r', 'e', '!']\n"
          ]
        }
      ],
      "source": [
        " # exercise 1\n",
        "text=\"Hi, there!\"\n",
        "tokens=list(text)\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# exercise 2: word tokenization\n",
        "text=\"It is unbelievably good!\"\n",
        "text=text.replace(\"!\",\"\")\n",
        "tokens=text.split(\" \")\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebPKREENxBY3",
        "outputId": "9a469332-16fc-42f0-ad27-6d5278e40215"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['It', 'is', 'unbelievably', 'good']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# exercise 3 :\n",
        "text=\"Hi, there!\"\n",
        "for x in list(\",!\"):\n",
        "    text=text.replace(f\"{x}\",f\" {x}\")\n",
        "tokens=text.split(\" \")\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8N_DVlpxJYu",
        "outputId": "104ae574-3c9e-4ea2-ea92-86f14ff7a13f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hi', ',', 'there', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download & clean up the text"
      ],
      "metadata": {
        "id": "431Sks85yHpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O anna.txt \"https://gitlab.com/amirbig44/pytorch-gan-course/-/raw/main/anna.txt?ref_type=heads&inline=false\" # text of anna karenina"
      ],
      "metadata": {
        "id": "rVqTxcr8xmDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"./anna.txt\",\"r\") as f:\n",
        "    text=f.read()\n",
        "words=text.split(\" \")\n",
        "print(words[:20])\n",
        "\n",
        "print(set(text.lower())) # unique characters in the text by set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awHgakl9xNo_",
        "outputId": "ef603b93-e030-4590-c5aa-6a2797eda64f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Chapter', '1\\n\\n\\nHappy', 'families', 'are', 'all', 'alike;', 'every', 'unhappy', 'family', 'is', 'unhappy', 'in', 'its', 'own\\nway.\\n\\nEverything', 'was', 'in', 'confusion', 'in', 'the', \"Oblonskys'\"]\n",
            "{'.', '7', 'a', 'x', 'o', ')', 'i', '-', '\\n', 'e', 'm', 'l', '3', 'b', '5', '?', 'y', \"'\", 't', ';', 'c', '2', 'j', '6', 'z', 'h', '9', '1', '\"', '_', ' ', '!', 'u', 'k', 'r', 'f', ',', '`', 'q', 'w', 'g', '(', ':', 'p', 'd', '0', '8', 'v', '4', 'n', 's'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_text=text.lower().replace(\"\\n\", \" \")\n",
        "clean_text=clean_text.replace(\"-\", \" \")\n",
        "for x in \",.:;?!$()/_&%*@'`\":\n",
        "    clean_text=clean_text.replace(f\"{x}\", f\" {x} \")\n",
        "clean_text=clean_text.replace('\"', ' \" ')\n",
        "text=clean_text.split()"
      ],
      "metadata": {
        "id": "_axkEgBUyBkz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "word_counts = Counter(text)\n",
        "\n",
        "words=sorted(word_counts, key=word_counts.get, reverse=True) # get unique words\n",
        "print(words[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDeygMNxyu9C",
        "outputId": "2659d980-1b76-48ab-d13c-6c80e8cc5317"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[',', '.', 'the', '\"', 'and', 'to', 'of', 'he', \"'\", 'a']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Here we will make two dictionaries where the key values ​​are in the same place We will use it further"
      ],
      "metadata": {
        "id": "NkSmWAOCzN38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_length =len(text)\n",
        "num_unique_words =len(words)\n",
        "print(f\"the text contains {text_length} words\")\n",
        "print(f\"there are {num_unique_words} unique tokens\")\n",
        "word_to_int={v:k for k,v in enumerate(words)} # k is number of word repetition and ,v is word\n",
        "int_to_word={k:v for k,v in enumerate(words)}\n",
        "print({k:v for k,v in word_to_int.items() if k in words[:10]})\n",
        "print({k:v for k,v in int_to_word.items() if v in words[:10]})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kRaZA_cyzsV",
        "outputId": "4634f891-991d-40b9-e8b7-8ebe41d7c459"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the text contains 437098 words\n",
            "there are 12778 unique tokens\n",
            "{',': 0, '.': 1, 'the': 2, '\"': 3, 'and': 4, 'to': 5, 'of': 6, 'he': 7, \"'\": 8, 'a': 9}\n",
            "{0: ',', 1: '.', 2: 'the', 3: '\"', 4: 'and', 5: 'to', 6: 'of', 7: 'he', 8: \"'\", 9: 'a'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[0:20])\n",
        "wordidx=[word_to_int[w] for w in text]\n",
        "print([word_to_int[w] for w in text[0:20]])  # The number of each word is the number of repetitions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFM7oOrGzJv1",
        "outputId": "3924e669-c3c0-4bd3-94df-6490e2a5b69e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['chapter', '1', 'happy', 'families', 'are', 'all', 'alike', ';', 'every', 'unhappy', 'family', 'is', 'unhappy', 'in', 'its', 'own', 'way', '.', 'everything', 'was']\n",
            "[208, 2755, 280, 2981, 83, 31, 2419, 35, 202, 685, 362, 38, 685, 10, 236, 147, 166, 1, 149, 12]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create batches of training data"
      ],
      "metadata": {
        "id": "eshoWUek0fsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "seq_len=100\n",
        "xys=[]\n",
        "for n in range(0, len(wordidx)-seq_len-1):  # 0 : 437098 -100 - 1\n",
        "    x = wordidx[n:n+seq_len]                # x= 0:100   y = 1:101\n",
        "    y = wordidx[n+1:n+seq_len+1]            # x= 1:101   y = 2:102\n",
        "    xys.append((torch.tensor(x),(torch.tensor(y))))"
      ],
      "metadata": {
        "id": "zkgfo1Xz0RDT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " from torch.utils.data import DataLoader\n",
        "\n",
        "torch.manual_seed(42)\n",
        "batch_size=32\n",
        "loader = DataLoader(xys, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "x,y=next(iter(loader))\n",
        "print(x)\n",
        "print(y)\n",
        "print(x.shape,y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvhpkC_o0kQ3",
        "outputId": "9c34001d-f13f-44b7-adef-55fb9ac7d9ba"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  39,   31,    2,  ...,  688,  142,    7],\n",
            "        [ 156, 5293,    0,  ...,   38,  330,    0],\n",
            "        [   3,   97,    0,  ...,    0, 1774,   34],\n",
            "        ...,\n",
            "        [  16,  156,    9,  ...,  113,    5,  533],\n",
            "        [   3,    4,   31,  ...,   98,    5,   98],\n",
            "        [ 289,   19,   23,  ...,    9,  828,  550]])\n",
            "tensor([[  31,    2, 2727,  ...,  142,    7,    0],\n",
            "        [5293,    0,   16,  ...,  330,    0,    3],\n",
            "        [  97,    0,    4,  ..., 1774,   34,    3],\n",
            "        ...,\n",
            "        [ 156,    9,  489,  ...,    5,  533,   27],\n",
            "        [   4,   31,   25,  ...,    5,   98,    1],\n",
            "        [  19,   23,    1,  ...,  828,  550,    1]])\n",
            "torch.Size([32, 100]) torch.Size([32, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tI-j3T_Z1u50"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}